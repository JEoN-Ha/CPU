{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595514434202",
   "display_name": "Python 3.7.7 64-bit ('cpuData': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 4.66 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "import openpyxl\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 1.56 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "cpuData_morph_KR = pd.read_csv('./NN_KR.csv')\n",
    "cpuData_morph_ENG = pd.read_csv('./NN_ENG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 1.57 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "cpuData_csv = pd.read_csv('./cpuDataSet.csv',  encoding = 'CP949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 5.24 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(len(cpuData_csv['대표청구항'])):\n",
    "    cpuData_csv['대표청구항'][i] = cpuData_csv['대표청구항'][i][9:]\n",
    "# cpuData_csv['대표청구항']\n",
    "for i in range(len(cpuData_csv['발명의 명칭'])):\n",
    "    cpuData_csv['발명의 명칭'][i] = re.sub(r'\\([^)]*\\)', '', cpuData_csv['발명의 명칭'][i])\n",
    "cpuData_KR = cpuData_csv[cpuData_csv['국가코드'].isin(['KR']) | cpuData_csv['국가코드'].isin(['JP'])]\n",
    "cpuData_ENG = cpuData_csv[cpuData_csv['국가코드'].isin(['CN']) | cpuData_csv['국가코드'].isin(['EP']) | cpuData_csv['국가코드'].isin(['US'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 46 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "cpuData_KR['꼬꼬마'] = cpuData_KR['발명의 명칭'] + ' ' + cpuData_KR['요약'] + cpuData_KR['대표청구항']\n",
    "# cpuData_csv['꼬꼬마'] = cpuData_csv['발명의 명칭'][:6887] + ' ' + cpuData_csv['요약'][:6887] + cpuData_csv['대표청구항'][:6887]\n",
    "# cpuData_csv['꼬꼬마'].drop(cpuData_csv['꼬꼬마'].index[6887:]) # 영어부분 삭제\n",
    "\n",
    "\n",
    "# # cpuData_csv['nltk'] = cpuData_csv['발명의 명칭'][6887:] + ' ' + cpuData_csv['요약'][6887:] + cpuData_csv['대표청구항'][6887:]\n",
    "# cpuData_csv['nltk'].drop(cpuData_csv['nltk'].index[:6887]) # 한글부분 삭제\n",
    "cpuData_ENG['nltk'] = cpuData_ENG['발명의 명칭'] + ' ' + cpuData_ENG['요약'] + cpuData_ENG['대표청구항']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 1 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "IPC_Number = [ipc[0:4] for ipc in cpuData_csv['메인 IPC'].values]\n",
    "Unique_IPC_Number = list(set(IPC_Number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 26 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "IPC_Probability = []\n",
    "for u in Unique_IPC_Number:\n",
    "    IPC_Probability.append((u, (IPC_Number.count(u) / len(IPC_Number))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 12min 42s\n"
    }
   ],
   "source": [
    "%%time\n",
    "cpuData_morph_list_KR = []\n",
    "cpuData_morph_cleaned_list_KR = []\n",
    "for i in range(len(cpuData_morph_KR)):\n",
    "    cpuData_morph_list_KR.append(cpuData_morph_KR.iloc[i][1:].tolist())\n",
    "for i in range(len(cpuData_morph_list_KR)):\n",
    "    cpuData_morph_cleaned_list_KR.append([x for x in cpuData_morph_list_KR if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 1h 34min 2s\n"
    }
   ],
   "source": [
    "%%time\n",
    "cpuData_morph_list_ENG = []\n",
    "cpuData_morph_cleaned_list_ENG = []\n",
    "for i in range(len(cpuData_morph_ENG)):\n",
    "    cpuData_morph_list_ENG.append(cpuData_morph_ENG.iloc[i][1:].tolist())\n",
    "for i in range(len(cpuData_morph_list_ENG)):\n",
    "    cpuData_morph_cleaned_list_ENG.append([x for x in cpuData_morph_list_ENG if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# for ipc, P_c in IPC_Probability:\n",
    "#     first_term = first_term + (P_c * np.log2(P_c))\n",
    "# first_term = first_term * -1\n",
    "# first_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# cpuData_list = []\n",
    "# for i in range(len(cpuData_morph_cleaned_list_KR)):\n",
    "#     cpuData_list = cpuData_list + cpuData_morph_cleaned_list_KR[i]\n",
    "# for i in range(len(cpuData_morph_cleaned_list_ENG)):\n",
    "#     cpuData_list = cpuData_list + cpuData_morph_cleaned_list_ENG\n",
    "# cpuData_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpuDF_KR = pd.DataFrame()\n",
    "cpuDF_KR['Data'] = cpuData_KR['꼬꼬마']\n",
    "cpuDF_KR['IPC'] = cpuData_KR['메인 IPC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "must be str, not list",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not list"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_KR = []\n",
    "for rows, Document in enumerate(cpuData_morph_cleaned_list_KR):\n",
    "    for t in Document:\n",
    "        count_t_of_all = str(cpuDF_KR['Data'].values).count(t) # 전체 문서에서 단어 t의 수\n",
    "        P_t = count_t_of_all / (len(cpuData_morph_cleaned_list_KR) + len(cpuData_morph_cleaned_list_ENG)) # 전체 문서에서 단어 t의 확률\n",
    "        p_not_t = 1 - P_t # 전체 문서에서 단어 t가 아닌 확률\n",
    "        sum_of_p_conditional_c_and_t = 0 # 조건부확률 P(c|t)의 합을 담을 공간\n",
    "        sum_of_p_conditional_c_and_not_t = 0 # 조건부확률 P(c| not t)의 합을 담을 공간\n",
    "        first_term = 0 # 첫째 항\n",
    "        for ipc, P_c in IPC_Probability:\n",
    "            if ipc == cpuDF_KR.iloc[rows,1][0:4]: # IPC가 같으면\n",
    "\n",
    "                c_and_t = cpuDF_KR.iloc[rows,0].count(t) # 해당하는 IPC에 대한 단어 t의 수\n",
    "                p_conditional_c_and_t = c_and_t / count_t_of_all # 해당하는 IPC에 대한 문서에서 단어 t의 수 / 전체 문서에서 단어 t의 수\n",
    "                sum_of_p_conditional_c_and_t += (p_conditional_c_and_t * np.log2(p_conditional_c_and_t)) # 조건부확률의 합 P(c|t) * log(P(c|t))\n",
    "\n",
    "                c_and_not_t = len(Document) - cpuDF_KR.iloc[rows,0].count(t)   # 문서 전체 단어 수에서 단어 t의 수를 뺌\n",
    "                p_conditional_c_and_not_t = c_and_not_t / count_t_of_all    # P(c| not t)를 구함\n",
    "                sum_of_p_conditional_c_and_not_t += (p_conditional_c_and_not_t * np.log2(p_conditional_c_and_not_t)) # P(c| not t) * log(P(c| not t))\n",
    "\n",
    "            first_term = first_term + (P_c * np.log2(P_c))\n",
    "        result_KR.append((t, (-1 * first_term) + (P_t * sum_of_p_conditional_c_and_t) + (p_not_t * sum_of_p_conditional_c_and_not_t)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "11"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "for rows, Document in enumerate(cpuData_morph_cleaned_list_KR):\n",
    "    print(Document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 27 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "result_df_KR = pd.DataFrame.from_records(result_KR)\n",
    "result_df_KR.to_csv('IG_KR.csv')\n",
    "result_df_KR.to_excel('IG_KR.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpuDF_ENG = pd.DataFrame()\n",
    "cpuDF_ENG['Data'] = cpuData_ENG['nltk']\n",
    "cpuDF_ENG['IPC'] = cpuData_ENG['메인 IPC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "must be str, not list",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not list"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_ENG = []\n",
    "for rows, Document in enumerate(cpuData_morph_cleaned_list_ENG):\n",
    "    for t in Document:\n",
    "        count_t_of_all = str(cpuDF_ENG['Data'].values).count(t) # 전체 문서에서 단어 t의 수\n",
    "        P_t = count_t_of_all / (len(cpuData_morph_cleaned_list_KR) + len(cpuData_morph_cleaned_list_ENG)) # 전체 문서에서 단어 t의 확률\n",
    "        p_not_t = 1 - P_t # 전체 문서에서 단어 t가 아닌 확률\n",
    "        sum_of_p_conditional_c_and_t = 0 # 조건부확률 P(c|t)의 합을 담을 공간\n",
    "        sum_of_p_conditional_c_and_not_t = 0 # 조건부확률 P(c| not t)의 합을 담을 공간\n",
    "        first_term = 0 # 첫째 항\n",
    "        for ipc, P_c in IPC_Probability:\n",
    "            if ipc == cpuDF_ENG.iloc[rows,1][0:4]: # IPC가 같으면\n",
    "\n",
    "                c_and_t = cpuDF_ENG.iloc[rows,0].count(t) # 해당하는 IPC에 대한 단어 t의 수\n",
    "                p_conditional_c_and_t = c_and_t / count_t_of_all # 해당하는 IPC에 대한 문서에서 단어 t의 수 / 전체 문서에서 단어 t의 수\n",
    "                sum_of_p_conditional_c_and_t += (p_conditional_c_and_t * np.log2(p_conditional_c_and_t)) # 조건부확률의 합 P(c|t) * log(P(c|t))\n",
    "\n",
    "                c_and_not_t = len(Document) - cpuDF_ENG.iloc[rows,0].count(t)   # 문서 전체 단어 수에서 단어 t의 수를 뺌\n",
    "                p_conditional_c_and_not_t = c_and_not_t / count_t_of_all    # P(c| not t)를 구함\n",
    "                sum_of_p_conditional_c_and_not_t += (p_conditional_c_and_not_t * np.log2(p_conditional_c_and_not_t)) # P(c| not t) * log(P(c| not t))\n",
    "\n",
    "            first_term = first_term + (P_c * np.log2(P_c))\n",
    "        result_ENG.append((t, (-1 * first_term) + (P_t * sum_of_p_conditional_c_and_t) + (p_not_t * sum_of_p_conditional_c_and_not_t)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 16 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "result_df_ENG = pd.DataFrame.from_records(result_ENG)\n",
    "result_df_ENG.to_csv('IG_ENG.csv')\n",
    "result_df_ENG.to_excel('IG_ENG.xlsx')"
   ]
  }
 ]
}